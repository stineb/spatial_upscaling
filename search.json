[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spatial upscaling",
    "section": "",
    "text": "The context\nCreating maps with large spatial, often global coverage based on a limited set of local measurements has become popular (Ludwig et al. 2023; Bastin et al. 2019; Hoogen et al. 2019; Steidinger et al. 2019). Digital soil mapping led the way by introducing the paradigm that (i) maps can be created based on a model that fits relationships between a locally measured variable of interest and a set of covariates, often environmental variables; and that (ii) global maps of these covariates are available and enable predicting with the fitted model to conditions (locations) for which no local measurements are available (Hengl et al. 2017). But how reliable are such predictions? And what determines the reliability of predictions to unobserved locations? How can this reliability, the prediction error, be estimated?\nWith digital soil mapping introduced in Block 3 of Applied Geodata Science 2, here we probe its fundamental modelling paradigm - spatial upscaling. We learn how we test a (machine learning) model with a view to what it is used for - the prediction task.\nThis is a block of the M.Sc.-level course Applied Geodata Science 2, offered at the Geography Institute of University Bern. This block serves to critically reflect on working with big data and using (black box) models. It does not introduce entirely new methods, but serves to apply methods learned in previous blocks and in Applied Geodata Science 1 for exploring and understanding the benefits and limits of (geo-) data science methods. Rather than a tutorial, this block comes in the form of literature study and working with the data yourself. All students are required to hand in the Report Exercise of this block.\n\n\n\n\nBastin, Jean-Francois, Yelena Finegold, Claude Garcia, Danilo Mollicone, Marcelo Rezende, Devin Routh, Constantin M. Zohner, and Thomas W. Crowther. 2019. “The Global Tree Restoration Potential.” Science 365 (6448): 76–79. https://doi.org/10.1126/science.aax0848.\n\n\nHengl, Tomislav, Jorge Mendes de Jesus, Gerard B. M. Heuvelink, Maria Ruiperez Gonzalez, Milan Kilibarda, Aleksandar Blagotić, Wei Shangguan, et al. 2017. “SoilGrids250m: Global Gridded Soil Information Based on Machine Learning.” Edited by Ben Bond-Lamberty. PLOS ONE 12 (2): e0169748. https://doi.org/10.1371/journal.pone.0169748.\n\n\nHoogen, Johan van den, Stefan Geisen, Devin Routh, Howard Ferris, Walter Traunspurger, David A. Wardle, Ron G. M. de Goede, et al. 2019. “Soil Nematode Abundance and Functional Group Composition at a Global Scale.” Nature 572 (7768): 194–98. https://doi.org/10.1038/s41586-019-1418-6.\n\n\nLudwig, Marvin, Alvaro Moreno-Martinez, Norbert Hölzel, Edzer Pebesma, and Hanna Meyer. 2023. “Assessing and Improving the Transferability of Current Global Spatial Prediction Models.” Global Ecology and Biogeography 32 (3): 356–68. https://doi.org/10.1111/geb.13635.\n\n\nSteidinger, B. S., T. W. Crowther, J. Liang, M. E. Van Nuland, G. D. A. Werner, P. B. Reich, G. J. Nabuurs, et al. 2019. “Climatic Controls of Decomposition Drive the Global Biogeography of Forest-Tree Symbioses.” Nature 569 (7756): 404–8. https://doi.org/10.1038/s41586-019-1128-0."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "1  The data",
    "section": "",
    "text": "We will use a dataset of leaf nitrogen (N) content, measured in the field. The leaf N content is central for understanding the photosynthesis rates and biogeochemical cycling of N and C in terrestrial ecosystems. A rich body of literature has investigated global patterns of leaf N across the Earth’s biomes and the relationships of leaf N to environmental factors. In recent years, leaf N data collected in the field by a large number of individual campaigns, has been collated into homogenised and analysis-ready data compilations. “Small data” has been made “big”. Thanks to the fact that these data are geolocalised, covariate data from files with global coverage can be extracted and used to complement the observational leaf N data and to model leaf N on the basis of environmental covariates.\nResearch in the our group (GECO, Institute of Geography University of Bern) has generated such analysis-ready leaf N data, complemented with environmental covariates, and made openly accessible on GitHub.\nLoad the data directly from its online source on GitHub.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf &lt;- readr::read_csv(\"https://raw.githubusercontent.com/stineb/leafnp_data/main/data/leafnp_tian_et_al.csv\")\n\nRows: 36414 Columns: 66\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (10): FunGroups, Dc_Db_Ec_Eb_Hf_Hg, tree_shrub_Herb, Family_New, Family,...\ndbl (56): lon, lat, leafN, leafP, LeafNP, Lat_Di_check_final, Lon_Di_check_f...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe will work with a limited subset of the variables available in the file, and with the data aggregated by sites (identified by their respective longitudes and latitudes):\n\nleafN: leaf nitrogen content, in mass-based concentration units (gN gDM\\(^{-1}\\))\nlon: longitude in decimal degrees east\nlat: latitude in decimal degrees north\nelv: Elevation above sea level (m)\nmat: mean annual temperature (degrees Celsius)\nmap: mean annual precipitation (mm yr\\(^{-1}\\))\nndep: atmospheric nitrogen deposition g m\\(^{-2}\\) yr\\(^{-1}\\)\nmai: mean annual daily irradiance \\(\\micro\\)mol m\\(^{-2}\\) s\\(^{-1}\\)\nSpecies: species name of the plant on which leaf N was measured\n\n\ncommon_species &lt;- df |&gt; \n  group_by(Species) |&gt; \n  summarise(count = n()) |&gt; \n  arrange(desc(count)) |&gt; \n  slice(1:50) |&gt; \n  pull(Species)\n\ndfs &lt;- df |&gt; \n  dplyr::select(leafN, lon, lat, elv, mat, map, ndep, mai, Species) |&gt; \n  filter(Species %in% common_species)\n  # group_by(lon, lat) |&gt; \n  # summarise(across(where(is.numeric), mean))\n\n# quick overview of data\nskimr::skim(dfs)\n\n\nData summary\n\n\nName\ndfs\n\n\nNumber of rows\n22472\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSpecies\n0\n1\n10\n23\n0\n50\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nleafN\n0\n1\n15.58\n5.11\n1.02\n12.22\n14.57\n17.50\n54.04\n▂▇▂▁▁\n\n\nlon\n0\n1\n18.08\n27.33\n-157.79\n5.24\n13.62\n19.95\n140.59\n▁▁▇▂▁\n\n\nlat\n0\n1\n48.35\n9.55\n-37.49\n43.00\n48.99\n52.44\n69.75\n▁▁▁▆▇\n\n\nelv\n0\n1\n494.28\n469.48\n-5.00\n135.00\n357.00\n716.00\n4847.90\n▇▂▁▁▁\n\n\nmat\n0\n1\n8.80\n3.76\n-4.88\n6.97\n8.64\n10.30\n29.96\n▁▇▅▁▁\n\n\nmap\n0\n1\n818.59\n314.40\n105.19\n607.29\n721.15\n955.24\n3641.73\n▇▅▁▁▁\n\n\nndep\n0\n1\n1.22\n0.51\n0.07\n0.82\n1.22\n1.55\n2.68\n▂▅▇▃▁\n\n\nmai\n0\n1\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n▅▇▃▁▁\n\n\n\n\n# show missing data\nvisdat::vis_miss(dfs)"
  },
  {
    "objectID": "exercise.html#literature",
    "href": "exercise.html#literature",
    "title": "2  Exercise",
    "section": "2.1 Literature",
    "text": "2.1 Literature\nRead the paper by Ludwig et al. (2023) and answer the following questions:\n\nExplain the difference between a random cross-validation and a spatial cross-validation.\nIn spatial upscaling, we model the target based on environmental covariates. This implies that we assume the training data to sufficiently represent the conditions on which the model will be applied for generating predictions. Prediction errors may increase with an increasing distance of the prediction location from the training locations. The paper by Ludwig et al. (2023) considers this “distance” as a geographical distance in Euclidian space. Do you see an alternative to measuring a distance that considers the task of spatial upscaling based on environmental covariates more directly?"
  },
  {
    "objectID": "exercise.html#random-cross-validation",
    "href": "exercise.html#random-cross-validation",
    "title": "2  Exercise",
    "section": "2.2 Random cross-validation",
    "text": "2.2 Random cross-validation\nUse Random Forest to perform a 5-fold cross-validation with the leaf N data (leafN) and the following predictors:\n\nelv: Elevation above sea level (m)\nmat: mean annual temperature (degrees Celsius)\nmap: mean annual precipitation (mm yr\\(^{-1}\\))\nndep: atmospheric nitrogen deposition g m\\(^{-2}\\) yr\\(^{-1}\\)\nmai: mean annual daily irradiance \\(\\micro\\)mol m\\(^{-2}\\) s\\(^{-1}\\)\nSpecies: species name of the plant on which leaf N was measured\n\nReport the mean RMSE and R\\(^2\\) across cross-validation folds. Chose hyperparameters as mtry = 3 and min.node.size = 12 and others as their default in ranger::ranger()."
  },
  {
    "objectID": "exercise.html#spatial-cross-validation",
    "href": "exercise.html#spatial-cross-validation",
    "title": "2  Exercise",
    "section": "2.3 Spatial cross-validation",
    "text": "2.3 Spatial cross-validation\nHere is the distribution of our data across the globe.\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\n# get coast outline\ncoast &lt;- rnaturalearth::ne_coastline(scale = 110, returnclass = \"sf\")\n\nggplot() +\n\n  # plot coastline\n  geom_sf(data = coast,\n          colour = 'black',\n          size = 0.2) +\n\n  # set extent in longitude and latitude\n  coord_sf(\n    ylim = c(-60, 80),\n    expand = FALSE) +  # to draw map strictly bounded by the specified extent\n  \n  # plot points on map\n  geom_point(data = dfs, aes(x = lon, y = lat), color = \"red\", size = 0.2) +\n  labs(x = \"\", y = \"\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\nFigure 2.1: Locations of data points.\n\n\n\n\n\nWhat do you observe? Discuss the potential implications of the geographical distribution of data points for spatial upscaling.\nPerform a spatial cross-validation. To do so, first identify geographical clusters of the data using the k-means algorithm (an unsupervised machine learning method), considering the longitude and latitude of data points and setting \\(k = 5\\). Plot points on a global map, showing the five clusters with distinct colors.\nPlot the distribution of leaf N by cluster.\nSplit your data into five folds that correspond to the geographical clusters identified by in (2.), and fit a random forest model with the same hyperparameters as above and performing a 5-fold cross-validation with the clusters as folds. Report the RMSE and the R\\(^2\\) determined on each of the five folds\nCompare the results of the spatial cross-validation to the results of the random cross-validation and discuss reasons for why you observe a difference in the cross-validation metrics (if you do).\n\n\n\n\n\n\n\nHint\n\n\n\nAn example for how to use k-means is given in the tutorial on land cover classification.\n\n\n\n\n\n\n\n\nHint\n\n\n\nUsing a pre-defined grouping for delineating the folds in k-fold cross-validation can be done by first determining the indexes of rows for each group (a list of vectors that contain the row indexes of the training data). This can be done by:\n\n# create folds based on clusters\n# assuming 'df' contains the data and a column called 'cluster' containing the \n# result of the k-means clustering\ngroup_folds_train &lt;- purrr::map(\n  seq(length(unique(df$cluster))),\n  ~ {\n    df |&gt; \n      select(cluster) |&gt; \n      mutate(idx = 1:n()) |&gt; \n      filter(cluster != .) |&gt; \n      pull(idx)\n  }\n)\n\ngroup_folds_test &lt;- purrr::map(\n  seq(length(unique(df$cluster))),\n  ~ {\n    df |&gt; \n      select(cluster) |&gt; \n      mutate(idx = 1:n()) |&gt; \n      filter(cluster == .) |&gt; \n      pull(idx)\n  }\n)\n\nThen, implement the custom cross-validation “by hand”. Code could look like this (But note that this is just for demo, and the code will not run without an error if you simply copy-and-paste. Complement in ... with your code):\n\n# create a function that trains a random forest model on a given set of rows and \n# predicts on a disjunct set of rows\ntrain_test_by_fold &lt;- function(df, idx_train, idx_val){\n  \n  mod &lt;- ranger::ranger(\n    x =  ...,  # data frame with columns corresponding to predictors\n    y =  ...   # a vector of the target values (not a data frame!)\n  )\n  \n  pred &lt;- predict(...,       # the fitted model object \n                  data = ... # a data frame with columns corresponding to predictors\n                  )\n\n  rsq &lt;- ...  # the R-squared determined on the validation set\n  rmse &lt;- ... # the root mean square error on the validation set\n  \n  return(tibble(rsq = rsq, rmse = rmse))\n}\n\n# apply function on each custom fold and collect validation results in a nice\n# data frame\nout &lt;- purrr::map2_dfr(\n  group_folds_train,\n  group_folds_test,\n  ~train_test_by_fold(.x, .y)\n) |&gt; \n  mutate(test_fold = 1:5)\n\n\n\n\n\n\n\n\n\nExpected Result\n\n\n\n\n\nThis is approximate because the k-means clustering contains a random element.\n\n# # A tibble: 5 × 3\n#      rsq  rmse test_fold\n#    &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;\n# 1 0.0233  7.05         1\n# 2 0.492   4.04         2\n# 3 0.619   3.28         3\n# 4 0.511   3.07         4\n# 5 0.168   2.26         5"
  },
  {
    "objectID": "exercise.html#environmental-cross-validation",
    "href": "exercise.html#environmental-cross-validation",
    "title": "2  Exercise",
    "section": "2.4 Environmental cross-validation",
    "text": "2.4 Environmental cross-validation\nThe central rationale for spatial uspcaling is that we can model based on relationships between the target variable and the environment. The geographic location is not among the predictors. Thus, as long as the training data covers a wide enough range of environmental conditions, we can model for any new location where environmental conditions are within that range, irrespective of its geographical position. The challenge is just that the training data often doesn’t cover all environmental conditions of the globe, yet upscaling is often done for the globe.\nAnyways, let’s probe the generalisability of a model not in geographical space, but in environmental space.\n\nTo do so, perform a custom cross-validation as above, but this time considering five clusters of points not in geographical space, but in environmental space - spanned by the mean annual precipitation and the mean annual temperature. Report the R-squared and the RMSE on the validation set of each of the five folds.\nCompare the results of the environmental cross-validation to the results of the random and the spatial cross-validation and discuss reasons for why you observe a difference in the cross-validation metrics (if you do).\n\n\n\n\n\n\n\nExpected Result\n\n\n\n\n\nThis is approximate because the k-means clustering contains a random element.\n\n# # A tibble: 5 × 3\n#     rsq  rmse test_fold\n#   &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;\n# 1 0.652  2.95         1\n# 2 0.659  3.20         2\n# 3 0.602  3.20         3\n# 4 0.514  3.79         4\n# 5 0.469  3.55         5\n\n\n\n\n\n\n\n\nLudwig, Marvin, Alvaro Moreno-Martinez, Norbert Hölzel, Edzer Pebesma, and Hanna Meyer. 2023. “Assessing and Improving the Transferability of Current Global Spatial Prediction Models.” Global Ecology and Biogeography 32 (3): 356–68. https://doi.org/10.1111/geb.13635."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bastin, Jean-Francois, Yelena Finegold, Claude Garcia, Danilo Mollicone,\nMarcelo Rezende, Devin Routh, Constantin M. Zohner, and Thomas W.\nCrowther. 2019. “The Global Tree Restoration Potential.”\nScience 365 (6448): 76–79. https://doi.org/10.1126/science.aax0848.\n\n\nHengl, Tomislav, Jorge Mendes de Jesus, Gerard B. M. Heuvelink, Maria\nRuiperez Gonzalez, Milan Kilibarda, Aleksandar Blagotić, Wei Shangguan,\net al. 2017. “SoilGrids250m: Global\nGridded Soil Information Based on Machine Learning.” Edited by\nBen Bond-Lamberty. PLOS ONE 12 (2): e0169748. https://doi.org/10.1371/journal.pone.0169748.\n\n\nHoogen, Johan van den, Stefan Geisen, Devin Routh, Howard Ferris, Walter\nTraunspurger, David A. Wardle, Ron G. M. de Goede, et al. 2019.\n“Soil Nematode Abundance and Functional Group Composition at a\nGlobal Scale.” Nature 572 (7768): 194–98. https://doi.org/10.1038/s41586-019-1418-6.\n\n\nLudwig, Marvin, Alvaro Moreno-Martinez, Norbert Hölzel, Edzer Pebesma,\nand Hanna Meyer. 2023. “Assessing and Improving the\nTransferability of Current Global Spatial Prediction Models.”\nGlobal Ecology and Biogeography 32 (3): 356–68. https://doi.org/10.1111/geb.13635.\n\n\nSteidinger, B. S., T. W. Crowther, J. Liang, M. E. Van Nuland, G. D. A.\nWerner, P. B. Reich, G. J. Nabuurs, et al. 2019. “Climatic\nControls of Decomposition Drive the Global Biogeography of Forest-Tree\nSymbioses.” Nature 569 (7756): 404–8. https://doi.org/10.1038/s41586-019-1128-0."
  }
]